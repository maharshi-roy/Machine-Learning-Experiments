{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Neural Machine Translation using LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1HelTzK5x_6q8uk0qmxzP533Di5H1hAWC",
      "authorship_tag": "ABX9TyPTo1CrpPJJs+er6sXjlNmJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maharshi-roy/Machine-Learning-Experiments/blob/main/Neural_Machine_Translation_using_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhoLQDkGgdx8"
      },
      "source": [
        "#Make imports\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "import os\n",
        "import seaborn as sns\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQNeTtWZlwUc",
        "outputId": "0be1428c-298b-4dc0-edb5-f3bd1da7dd1c"
      },
      "source": [
        "#TPU settings\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.TPUStrategy(tpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.6.0\n",
            "Running on TPU  ['10.12.249.242:8470']\n",
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.12.249.242:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.12.249.242:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-_bF5bilI2f"
      },
      "source": [
        "def preprocess(text):\n",
        "  text = ''.join(ch for ch in text if ch not in string.punctuation)\n",
        "  text = text.lower()\n",
        "  text = re.sub(r'\\d','',text)\n",
        "  text = re.sub(r'\\s+',' ',text)\n",
        "  text = text.strip()\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKe9ncQoZfox"
      },
      "source": [
        "#Extract dataset and preprocess\n",
        "dataset_root = \"./drive/MyDrive/ml/datasets/\"\n",
        "\n",
        "if os.path.exists(dataset_root + \"parallel/preprocessed_data.pickle\"):\n",
        "  with open(dataset_root + \"parallel/preprocessed_data.pickle\", 'rb') as f:\n",
        "    english_sentences, hindi_sentences = pickle.load(f)\n",
        "else:\n",
        "  if not os.path.exists(dataset_root + \"parallel/IITB.en-hi.en\"):\n",
        "    os.system(\"tar -xzf \" + dataset_root + \"parallel.tgz -C \" + dataset_root)\n",
        "\n",
        "  with open(dataset_root + \"parallel/IITB.en-hi.en\",'r') as f:\n",
        "    english_sentences = f.read().split('\\n')\n",
        "\n",
        "  with open(dataset_root + \"parallel/IITB.en-hi.hi\",'r') as f:\n",
        "    hindi_sentences = f.read().split('\\n')\n",
        "\n",
        "  english_sentences = [preprocess(en) for en in english_sentences]\n",
        "  hindi_sentences = ['<START> ' + re.sub('[a-zA-Z]','',preprocess(hi)) + ' <END>' for hi in hindi_sentences]\n",
        "\n",
        "  #Remove duplicate sentences\n",
        "  english_unique = set()\n",
        "  english_sentences_temp = []\n",
        "  hindi_sentences_temp = []\n",
        "  l = len(english_sentences)\n",
        "  for i in range(l):\n",
        "    if english_sentences[i] not in english_unique:\n",
        "      english_unique.add(english_sentences[i])\n",
        "      english_sentences_temp.append(english_sentences[i])\n",
        "      hindi_sentences_temp.append(hindi_sentences[i])\n",
        "\n",
        "  english_sentences = english_sentences_temp\n",
        "  hindi_sentences = hindi_sentences_temp\n",
        "  \n",
        "  with open(dataset_root + \"parallel/preprocessed_data.pickle\",'wb') as f:\n",
        "    pickle.dump((english_sentences, hindi_sentences), f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsf6EbkWZDUY",
        "outputId": "d90e379b-d6e3-4bd9-ed43-4626b8a7d0a7"
      },
      "source": [
        "print(len(english_sentences), len(hindi_sentences))\n",
        "print()\n",
        "english_sentences[:3], hindi_sentences[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "998998 998998\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['give your application an accessibility workout',\n",
              "  'accerciser accessibility explorer',\n",
              "  'the default plugin layout for the bottom panel'],\n",
              " ['<START> अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें <END>',\n",
              "  '<START> एक्सेर्साइसर पहुंचनीयता अन्वेषक <END>',\n",
              "  '<START> निचले पटल के लिए डिफोल्ट प्लगइन खाका <END>'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjnK8XArDPUe"
      },
      "source": [
        "#Some parameters\n",
        "vocab_size = 10000\n",
        "total_sentences = 25000\n",
        "maxlen = 10\n",
        "epochs = 70\n",
        "validation_split = 0.05"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyHjYB_eMpD7"
      },
      "source": [
        "en_data = []\n",
        "hi_data = []\n",
        "\n",
        "cnt = 0\n",
        "\n",
        "for (en,hi) in zip(english_sentences, hindi_sentences):\n",
        "  l = min(len(en.split()), len(hi.split()))\n",
        "  if l <= maxlen:\n",
        "    en_data.append(en)\n",
        "    hi_data.append(hi)\n",
        "    cnt += 1\n",
        "  if cnt == total_sentences:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwR2rlOvB-xZ",
        "outputId": "f3c6d24a-d13b-46bd-ea0a-584f889bf7d5"
      },
      "source": [
        "#Tokenize the texts and convert to sequences\n",
        "en_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<OOV>', lower=False)\n",
        "en_tokenizer.fit_on_texts(en_data)\n",
        "en_sequences = en_tokenizer.texts_to_sequences(en_data)\n",
        "\n",
        "hi_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<OOV>', lower=False)\n",
        "hi_tokenizer.fit_on_texts(hi_data)\n",
        "hi_sequences = hi_tokenizer.texts_to_sequences(hi_data)\n",
        "\n",
        "english_vocab_size = len(en_tokenizer.word_index) + 1\n",
        "hindi_vocab_size = len(hi_tokenizer.word_index) + 1\n",
        "print(\"English Vocab Size: \", english_vocab_size)\n",
        "print(\"Hindi Vocab Size: \", hindi_vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Vocab Size:  8020\n",
            "Hindi Vocab Size:  9395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luUa7TE6RYFq"
      },
      "source": [
        "#Prepare encoder data\n",
        "encoder_inputs = tf.keras.preprocessing.sequence.pad_sequences(en_sequences, maxlen=maxlen, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olIjin62TPF7"
      },
      "source": [
        "#Prepare decoder data\n",
        "decoder_inputs = []\n",
        "decoder_outputs = []\n",
        "\n",
        "for hi in hi_sequences:\n",
        "  decoder_inputs.append(hi[:-1])\n",
        "  decoder_outputs.append(hi[1:])\n",
        "\n",
        "decoder_inputs = tf.keras.preprocessing.sequence.pad_sequences(decoder_inputs, maxlen=maxlen, padding='post')\n",
        "decoder_outputs = tf.keras.preprocessing.sequence.pad_sequences(decoder_outputs, maxlen=maxlen, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5OWbUrPRENr",
        "outputId": "44294d4c-4389-4e30-a210-5cfda4b3edac"
      },
      "source": [
        "# Training and Testing split\n",
        "# 95%, 5%\n",
        "split = int(0.95 * total_sentences)\n",
        "\n",
        "X_train = [encoder_inputs[:split], decoder_inputs[:split]]\n",
        "y_train = decoder_outputs[:split]\n",
        "\n",
        "# Test data to evaluate our NMT model using BLEU score\n",
        "X_test = en_data[:split]\n",
        "y_test = hi_data[:split]\n",
        "\n",
        "print(X_train[0].shape, X_train[1].shape, y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(23750, 10) (23750, 10) (23750, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUboXx8WjDnP",
        "outputId": "1db42787-6c35-42cf-b9ca-b892bdc21935"
      },
      "source": [
        "#Define LSTM model\n",
        "d_model = 256\n",
        "\n",
        "#Encoder\n",
        "inputs = tf.keras.layers.Input(shape=(None,))\n",
        "x = tf.keras.layers.Embedding(english_vocab_size, d_model, mask_zero=True)(inputs)\n",
        "_,state_h,state_c = tf.keras.layers.LSTM(d_model,activation='relu',return_state=True)(x)\n",
        "\n",
        "#Decoder\n",
        "targets = tf.keras.layers.Input(shape=(None,))\n",
        "embedding_layer = tf.keras.layers.Embedding(hindi_vocab_size, d_model, mask_zero=True)\n",
        "x = embedding_layer(targets)\n",
        "decoder_lstm = tf.keras.layers.LSTM(d_model,activation='relu',return_sequences=True, return_state=True)\n",
        "x,_,_ = decoder_lstm(x, initial_state=[state_h, state_c])\n",
        "dense1 = tf.keras.layers.Dense(hindi_vocab_size, activation='softmax')\n",
        "x = dense1(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=[inputs, targets],outputs=x)\n",
        "model.summary()\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "model.compile(optimizer='rmsprop', loss=loss, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 256)    2053120     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 256)    2405120     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 256), (None, 525312      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 256),  525312      embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 9395)   2414515     lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 7,923,379\n",
            "Trainable params: 7,923,379\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq3TUpTK3TRE"
      },
      "source": [
        "#Save model after each epoch\n",
        "save_model_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='./drive/MyDrive/ml/models/en-hi.h5',\n",
        "    monitor='val_accuracy',\n",
        "    mode='max'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxsPj7SL1f-b",
        "outputId": "0a7c3193-05fc-4909-e2c7-4f6144dd7a01"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=epochs, validation_split=validation_split, callbacks=[save_model_callback, tf.keras.callbacks.TerminateOnNaN()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "706/706 [==============================] - 44s 58ms/step - loss: 3.1307 - accuracy: 0.2264 - val_loss: 2.2962 - val_accuracy: 0.2796\n",
            "Epoch 2/70\n",
            "706/706 [==============================] - 40s 57ms/step - loss: 2.4292 - accuracy: 0.2835 - val_loss: 2.2112 - val_accuracy: 0.3167\n",
            "Epoch 3/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 2.2675 - accuracy: 0.3163 - val_loss: 2.1736 - val_accuracy: 0.3258\n",
            "Epoch 4/70\n",
            "706/706 [==============================] - 40s 57ms/step - loss: 2.1440 - accuracy: 0.3450 - val_loss: 2.1479 - val_accuracy: 0.3438\n",
            "Epoch 5/70\n",
            "706/706 [==============================] - 40s 57ms/step - loss: 2.0371 - accuracy: 0.3720 - val_loss: 2.1238 - val_accuracy: 0.3526\n",
            "Epoch 6/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 1.9442 - accuracy: 0.3972 - val_loss: 2.1193 - val_accuracy: 0.3588\n",
            "Epoch 7/70\n",
            "706/706 [==============================] - 40s 57ms/step - loss: 1.8573 - accuracy: 0.4198 - val_loss: 2.1479 - val_accuracy: 0.3592\n",
            "Epoch 8/70\n",
            "706/706 [==============================] - 40s 57ms/step - loss: 1.7760 - accuracy: 0.4425 - val_loss: 2.1057 - val_accuracy: 0.3652\n",
            "Epoch 9/70\n",
            "706/706 [==============================] - 40s 57ms/step - loss: 1.6996 - accuracy: 0.4627 - val_loss: 2.1375 - val_accuracy: 0.3597\n",
            "Epoch 10/70\n",
            "706/706 [==============================] - 41s 57ms/step - loss: 1.6272 - accuracy: 0.4832 - val_loss: 2.1414 - val_accuracy: 0.3627\n",
            "Epoch 11/70\n",
            "706/706 [==============================] - 40s 57ms/step - loss: 1.5574 - accuracy: 0.5015 - val_loss: 2.2041 - val_accuracy: 0.3609\n",
            "Epoch 12/70\n",
            "706/706 [==============================] - 40s 57ms/step - loss: 1.4885 - accuracy: 0.5198 - val_loss: 2.1897 - val_accuracy: 0.3639\n",
            "Epoch 13/70\n",
            "706/706 [==============================] - 40s 57ms/step - loss: 1.4190 - accuracy: 0.5379 - val_loss: 2.1815 - val_accuracy: 0.3629\n",
            "Epoch 14/70\n",
            "706/706 [==============================] - 41s 59ms/step - loss: 1.3482 - accuracy: 0.5577 - val_loss: 2.2420 - val_accuracy: 0.3599\n",
            "Epoch 15/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 1.2782 - accuracy: 0.5760 - val_loss: 2.2578 - val_accuracy: 0.3470\n",
            "Epoch 16/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 1.2107 - accuracy: 0.5947 - val_loss: 2.2954 - val_accuracy: 0.3361\n",
            "Epoch 17/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 1.1439 - accuracy: 0.6141 - val_loss: 2.4156 - val_accuracy: 0.3339\n",
            "Epoch 18/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 1.0828 - accuracy: 0.6315 - val_loss: 2.4708 - val_accuracy: 0.3152\n",
            "Epoch 19/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 1.0311 - accuracy: 0.6486 - val_loss: 2.6007 - val_accuracy: 0.2916\n",
            "Epoch 20/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.9761 - accuracy: 0.6663 - val_loss: 2.6048 - val_accuracy: 0.3090\n",
            "Epoch 21/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.9262 - accuracy: 0.6817 - val_loss: 2.7206 - val_accuracy: 0.3067\n",
            "Epoch 22/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.8744 - accuracy: 0.6960 - val_loss: 2.8133 - val_accuracy: 0.2878\n",
            "Epoch 23/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.8230 - accuracy: 0.7091 - val_loss: 2.7313 - val_accuracy: 0.2944\n",
            "Epoch 24/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.7729 - accuracy: 0.7227 - val_loss: 2.9761 - val_accuracy: 0.2788\n",
            "Epoch 25/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.7324 - accuracy: 0.7362 - val_loss: 2.9223 - val_accuracy: 0.2856\n",
            "Epoch 26/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.6924 - accuracy: 0.7471 - val_loss: 3.0656 - val_accuracy: 0.2811\n",
            "Epoch 27/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.6506 - accuracy: 0.7571 - val_loss: 3.1921 - val_accuracy: 0.2633\n",
            "Epoch 28/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.6127 - accuracy: 0.7675 - val_loss: 3.2089 - val_accuracy: 0.2837\n",
            "Epoch 29/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.5769 - accuracy: 0.7773 - val_loss: 3.3387 - val_accuracy: 0.2697\n",
            "Epoch 30/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.5465 - accuracy: 0.7873 - val_loss: 3.6757 - val_accuracy: 0.3021\n",
            "Epoch 31/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.5111 - accuracy: 0.7972 - val_loss: 3.4730 - val_accuracy: 0.2712\n",
            "Epoch 32/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.4803 - accuracy: 0.8052 - val_loss: 3.6741 - val_accuracy: 0.2661\n",
            "Epoch 33/70\n",
            "706/706 [==============================] - 41s 59ms/step - loss: 0.4524 - accuracy: 0.8145 - val_loss: 4.3070 - val_accuracy: 0.2815\n",
            "Epoch 34/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.4285 - accuracy: 0.8242 - val_loss: 3.8753 - val_accuracy: 0.2753\n",
            "Epoch 35/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.4066 - accuracy: 0.8303 - val_loss: 4.4977 - val_accuracy: 0.2781\n",
            "Epoch 36/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.3802 - accuracy: 0.8392 - val_loss: 4.0872 - val_accuracy: 0.2856\n",
            "Epoch 37/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.3764 - accuracy: 0.8466 - val_loss: 4.2080 - val_accuracy: 0.2689\n",
            "Epoch 38/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.3366 - accuracy: 0.8529 - val_loss: 4.2223 - val_accuracy: 0.2642\n",
            "Epoch 39/70\n",
            "706/706 [==============================] - 41s 59ms/step - loss: 0.3178 - accuracy: 0.8608 - val_loss: 4.6136 - val_accuracy: 0.2558\n",
            "Epoch 40/70\n",
            "706/706 [==============================] - 42s 59ms/step - loss: 0.3065 - accuracy: 0.8637 - val_loss: 4.7233 - val_accuracy: 0.2717\n",
            "Epoch 41/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.2913 - accuracy: 0.8678 - val_loss: 4.7839 - val_accuracy: 0.2541\n",
            "Epoch 42/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.2844 - accuracy: 0.8708 - val_loss: 5.0821 - val_accuracy: 0.2629\n",
            "Epoch 43/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.2739 - accuracy: 0.8760 - val_loss: 6.1439 - val_accuracy: 0.2562\n",
            "Epoch 44/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.2711 - accuracy: 0.8765 - val_loss: 5.5134 - val_accuracy: 0.2588\n",
            "Epoch 45/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.3130 - accuracy: 0.8809 - val_loss: 5.4314 - val_accuracy: 0.2601\n",
            "Epoch 46/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.2582 - accuracy: 0.8834 - val_loss: 6.1720 - val_accuracy: 0.2571\n",
            "Epoch 47/70\n",
            "706/706 [==============================] - 42s 59ms/step - loss: 0.2493 - accuracy: 0.8852 - val_loss: 6.9788 - val_accuracy: 0.2687\n",
            "Epoch 48/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.2435 - accuracy: 0.8888 - val_loss: 6.6272 - val_accuracy: 0.2635\n",
            "Epoch 49/70\n",
            "706/706 [==============================] - 41s 59ms/step - loss: 0.2422 - accuracy: 0.8916 - val_loss: 6.6674 - val_accuracy: 0.2616\n",
            "Epoch 50/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.2384 - accuracy: 0.8916 - val_loss: 5.9298 - val_accuracy: 0.2506\n",
            "Epoch 51/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.2390 - accuracy: 0.8948 - val_loss: 6.4703 - val_accuracy: 0.2618\n",
            "Epoch 52/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.2224 - accuracy: 0.8969 - val_loss: 6.7088 - val_accuracy: 0.2560\n",
            "Epoch 53/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.2221 - accuracy: 0.8988 - val_loss: 6.2297 - val_accuracy: 0.2607\n",
            "Epoch 54/70\n",
            "706/706 [==============================] - 41s 59ms/step - loss: 0.2435 - accuracy: 0.9005 - val_loss: 6.6132 - val_accuracy: 0.2534\n",
            "Epoch 55/70\n",
            "706/706 [==============================] - 42s 60ms/step - loss: 0.2140 - accuracy: 0.9014 - val_loss: 7.2720 - val_accuracy: 0.2569\n",
            "Epoch 56/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.2198 - accuracy: 0.9011 - val_loss: 9.5836 - val_accuracy: 0.2620\n",
            "Epoch 57/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.2062 - accuracy: 0.9051 - val_loss: 8.5182 - val_accuracy: 0.2573\n",
            "Epoch 58/70\n",
            "706/706 [==============================] - 41s 58ms/step - loss: 0.2683 - accuracy: 0.9056 - val_loss: 6.2613 - val_accuracy: 0.2614\n",
            "Epoch 59/70\n",
            "706/706 [==============================] - 41s 59ms/step - loss: 0.2292 - accuracy: 0.9076 - val_loss: 6.8015 - val_accuracy: 0.2652\n",
            "Epoch 60/70\n",
            "706/706 [==============================] - 42s 59ms/step - loss: 0.1990 - accuracy: 0.9084 - val_loss: 9.3904 - val_accuracy: 0.2545\n",
            "Epoch 61/70\n",
            "706/706 [==============================] - 42s 59ms/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 15.3000 - val_accuracy: 0.2519\n",
            "Epoch 62/70\n",
            "706/706 [==============================] - 41s 59ms/step - loss: 4.0101 - accuracy: 0.9052 - val_loss: 8.6862 - val_accuracy: 0.2603\n",
            "Epoch 63/70\n",
            "706/706 [==============================] - 41s 59ms/step - loss: 47.3134 - accuracy: 0.9088 - val_loss: 9.8929 - val_accuracy: 0.2386\n",
            "Epoch 64/70\n",
            "706/706 [==============================] - 42s 59ms/step - loss: 0.2175 - accuracy: 0.9052 - val_loss: 15.4011 - val_accuracy: 0.2511\n",
            "Epoch 65/70\n",
            "706/706 [==============================] - 42s 59ms/step - loss: 0.2228 - accuracy: 0.9038 - val_loss: 14.2657 - val_accuracy: 0.2536\n",
            "Epoch 66/70\n",
            "706/706 [==============================] - 41s 59ms/step - loss: 0.2511 - accuracy: 0.9011 - val_loss: 18.4791 - val_accuracy: 0.2629\n",
            "Epoch 67/70\n",
            "706/706 [==============================] - 41s 59ms/step - loss: 0.2460 - accuracy: 0.8989 - val_loss: 12.5304 - val_accuracy: 0.2504\n",
            "Epoch 68/70\n",
            "706/706 [==============================] - 42s 59ms/step - loss: 0.2589 - accuracy: 0.8974 - val_loss: 20.4250 - val_accuracy: 0.2418\n",
            "Epoch 69/70\n",
            "706/706 [==============================] - 42s 59ms/step - loss: 0.2676 - accuracy: 0.8927 - val_loss: 12.2656 - val_accuracy: 0.2588\n",
            "Epoch 70/70\n",
            "706/706 [==============================] - 42s 59ms/step - loss: 0.2652 - accuracy: 0.8969 - val_loss: 14.5702 - val_accuracy: 0.2530\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d0ba00a90>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx0r37V9fshH",
        "outputId": "9b1f15a0-2675-41e1-cedf-9bbb550af9df"
      },
      "source": [
        "#Retrieve previously saved stuff\n",
        "saved_model = tf.keras.models.load_model('./drive/MyDrive/ml/models/en-hi.h5')\n",
        "\n",
        "saved_model.summary()\n",
        "\n",
        "inputs = saved_model.get_layer('input_1').output\n",
        "_,state_h,state_c = saved_model.get_layer('lstm').output\n",
        "targets = saved_model.get_layer('input_2').output\n",
        "embedding_layer = saved_model.get_layer('embedding_1')\n",
        "decoder_lstm = saved_model.get_layer('lstm_1')\n",
        "dense1 = saved_model.get_layer('dense')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 256)    2053120     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 256)    2405120     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 256), (None, 525312      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 256),  525312      embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 9395)   2414515     lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 7,923,379\n",
            "Trainable params: 7,923,379\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBvZo1SRzHbU"
      },
      "source": [
        "#Inference Model\n",
        "\n",
        "#Encoder\n",
        "encoder = tf.keras.models.Model(inputs, [state_h, state_c])\n",
        "\n",
        "#Decoder\n",
        "decoder_input_h = tf.keras.layers.Input(shape=(d_model,))\n",
        "decoder_input_c = tf.keras.layers.Input(shape=(d_model,))\n",
        "x = embedding_layer(targets)\n",
        "x, decoder_output_h, decoder_output_c = decoder_lstm(x, initial_state=[decoder_input_h, decoder_input_c])\n",
        "x = dense1(x)\n",
        "decoder = tf.keras.models.Model([targets] + [decoder_input_h, decoder_input_c], \n",
        "                                [x] + [decoder_output_h, decoder_output_c])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM4WlWIkXbS4"
      },
      "source": [
        "def predict_sentence(en_input):\n",
        "  input_seq = en_tokenizer.texts_to_sequences([en_input])\n",
        "\n",
        "  next_h, next_c = encoder.predict(input_seq)\n",
        "\n",
        "  curr_token = np.zeros(1)\n",
        "  curr_token[0] = hi_tokenizer.word_index['<START>']\n",
        "\n",
        "  pred_sentence = ''\n",
        "\n",
        "  for i in range(maxlen):\n",
        "    output, next_h, next_c = decoder.predict([curr_token] + [next_h, next_c])\n",
        "    next_token = np.argmax(output[0, 0, :])\n",
        "    next_word = hi_tokenizer.index_word[next_token]\n",
        "    if next_word == '<END>':\n",
        "      break\n",
        "    else:\n",
        "      pred_sentence += ' ' + next_word\n",
        "      curr_token[0] = next_token\n",
        "\n",
        "  return pred_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyPhikavuV5o"
      },
      "source": [
        "#Set up google translate as an additional reference\n",
        "from google.cloud import translate_v2 as translate\n",
        "\n",
        "translate_client = translate.Client.from_service_account_json(\"./drive/MyDrive/gcloud-auth-files/data-shard-330609-2669b6f2c900.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq5OesbI4pd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd364d70-8ed1-4d30-ea97-3f1504340535"
      },
      "source": [
        "#Testing and Analysis\n",
        "import nltk\n",
        "\n",
        "candidates = []\n",
        "references = []\n",
        "\n",
        "ctr = 20 \n",
        "i = 0\n",
        "\n",
        "while ctr>0:\n",
        "  l = len(X_test[i].split())\n",
        "  if l<=maxlen:   #Choose only sentences of length in range [5,15]\n",
        "    pred_sentence = predict_sentence(X_test[i])\n",
        "    candidates.append(pred_sentence.split())\n",
        "\n",
        "    print(\"Input: \", X_test[i])\n",
        "    print(\"Prediction: \", pred_sentence)\n",
        "\n",
        "    google_translated_sentence = translate_client.translate(X_test[i], target_language='hi')['translatedText']\n",
        "    \n",
        "    print(\"Google Translated Reference: \", google_translated_sentence)\n",
        "    print(\"Dataset Reference: \", ' '.join(y_test[i].split()[1:-1]))\n",
        "    print()\n",
        "    references.append([y_test[i].split()[1:-1], google_translated_sentence.split()])\n",
        "\n",
        "    ctr -= 1\n",
        "  i += 1\n",
        "\n",
        "print(nltk.translate.bleu_score.corpus_bleu(references, candidates))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  give your application an accessibility workout\n",
            "Prediction:   अपने अनुप्रयोग को पहुंचनीयता करें\n",
            "Google Translated Reference:  अपने एप्लिकेशन को एक्सेसिबिलिटी वर्कआउट दें\n",
            "Dataset Reference:  अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें\n",
            "\n",
            "Input:  accerciser accessibility explorer\n",
            "Prediction:   एक्सेर्साइसर पहुंचनीयता अन्वेषक\n",
            "Google Translated Reference:  accerciser अभिगम्यता एक्सप्लोरर\n",
            "Dataset Reference:  एक्सेर्साइसर पहुंचनीयता अन्वेषक\n",
            "\n",
            "Input:  the default plugin layout for the bottom panel\n",
            "Prediction:   ऊपरी पटल के लिए डिफोल्ट प्लगइन खाका\n",
            "Google Translated Reference:  निचले पैनल के लिए डिफ़ॉल्ट प्लगइन लेआउट\n",
            "Dataset Reference:  निचले पटल के लिए डिफोल्ट प्लगइन खाका\n",
            "\n",
            "Input:  the default plugin layout for the top panel\n",
            "Prediction:   ऊपरी पटल के लिए डिफोल्ट प्लगइन खाका\n",
            "Google Translated Reference:  शीर्ष पैनल के लिए डिफ़ॉल्ट प्लगइन लेआउट\n",
            "Dataset Reference:  ऊपरी पटल के लिए डिफोल्ट प्लगइन खाका\n",
            "\n",
            "Input:  a list of plugins that are disabled by default\n",
            "Prediction:   नही गया प्रकार सूची प्रकार यह अक्षर है\n",
            "Google Translated Reference:  प्लगइन्स की एक सूची जो डिफ़ॉल्ट रूप से अक्षम हैं\n",
            "Dataset Reference:  उन प्लगइनों की सूची जिन्हें डिफोल्ट रूप से निष्क्रिय किया गया है\n",
            "\n",
            "Input:  highlight duration\n",
            "Prediction:   अवधि को हाइलाइट रकें\n",
            "Google Translated Reference:  हाइलाइट अवधि\n",
            "Dataset Reference:  अवधि को हाइलाइट रकें\n",
            "\n",
            "Input:  the duration of the highlight box when selecting accessible nodes\n",
            "Prediction:   अनुमति दी गए नोड के प्रमाणपत्र को समर्थन करता करता\n",
            "Google Translated Reference:  सुलभ नोड्स का चयन करते समय हाइलाइट बॉक्स की अवधि\n",
            "Dataset Reference:  पहुंचनीय आसंधि नोड को चुनते समय हाइलाइट बक्से की अवधि\n",
            "\n",
            "Input:  highlight border color\n",
            "Prediction:   सीमांत रंग गेन\n",
            "Google Translated Reference:  सीमा रंग हाइलाइट करें\n",
            "Dataset Reference:  सीमांत बोर्डर के रंग को हाइलाइट करें\n",
            "\n",
            "Input:  the color and opacity of the highlight border\n",
            "Prediction:   हाइलाइट किए गए सीमांत का रंग और अपारदर्शिता।\n",
            "Google Translated Reference:  हाइलाइट बॉर्डर का रंग और अस्पष्टता\n",
            "Dataset Reference:  हाइलाइट किए गए सीमांत का रंग और अपारदर्शिता।\n",
            "\n",
            "Input:  highlight fill color\n",
            "Prediction:   भराई के रंग को हाइलाइट करें\n",
            "Google Translated Reference:  हाइलाइट भरें रंग\n",
            "Dataset Reference:  भराई के रंग को हाइलाइट करें\n",
            "\n",
            "Input:  the color and opacity of the highlight fill\n",
            "Prediction:   हाइलाइट बक्से और हाइलाइट बक्से का रंग\n",
            "Google Translated Reference:  हाइलाइट भरने का रंग और अस्पष्टता\n",
            "Dataset Reference:  हाइलाइट किया गया भराई का रंग और पारदर्शिता।\n",
            "\n",
            "Input:  api browser\n",
            "Prediction:   नया विचरक\n",
            "Google Translated Reference:  एपीआई ब्राउज़र\n",
            "Dataset Reference:  एपीआई विचरक\n",
            "\n",
            "Input:  browse the various methods of the current accessible\n",
            "Prediction:   क्षैतिज गणना की अदृश्य\n",
            "Google Translated Reference:  वर्तमान पहुंच के विभिन्न तरीकों को ब्राउज़ करें\n",
            "Dataset Reference:  इस समय जिसे प्राप्त किया गया हो उसकी विभिन्न विधियों मेथड में विचरण करें\n",
            "\n",
            "Input:  hide private attributes\n",
            "Prediction:   निजी गुणों को छिपाएं\n",
            "Google Translated Reference:  निजी विशेषताओं को छुपाएं\n",
            "Dataset Reference:  निजी गुणों को छिपाएं\n",
            "\n",
            "Input:  method\n",
            "Prediction:   विधि\n",
            "Google Translated Reference:  तरीका\n",
            "Dataset Reference:  विधि\n",
            "\n",
            "Input:  property\n",
            "Prediction:   गुणधर्म\n",
            "Google Translated Reference:  संपत्ति\n",
            "Dataset Reference:  गुणधर्म\n",
            "\n",
            "Input:  value\n",
            "Prediction:   मान\n",
            "Google Translated Reference:  मूल्य\n",
            "Dataset Reference:  मान\n",
            "\n",
            "Input:  ipython console\n",
            "Prediction:   फ़ोल्डर\n",
            "Google Translated Reference:  आईपीथॉन कंसोल\n",
            "Dataset Reference:  आईपाइथन कन्सोल\n",
            "\n",
            "Input:  interactive console for manipulating currently selected accessible\n",
            "Prediction:   चयनित चैनल के लिए चुना गया था\n",
            "Google Translated Reference:  वर्तमान में चयनित सुलभ में हेरफेर करने के लिए इंटरैक्टिव कंसोल\n",
            "Dataset Reference:  इस समय चुने गए एक्सेसेबेल से काम लेने के लिए अंतर्क्रियात्मक कन्सोल\n",
            "\n",
            "Input:  event monitor\n",
            "Prediction:   घटना मानिटर\n",
            "Google Translated Reference:  घटना की निगरानी\n",
            "Dataset Reference:  घटना मानिटर\n",
            "\n",
            "0.4197909502779101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgblcYZIllR6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}